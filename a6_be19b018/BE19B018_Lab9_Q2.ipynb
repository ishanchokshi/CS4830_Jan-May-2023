{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbsxSSWua3qB"
      },
      "source": [
        "Install Dependencies and Import Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dz907NVoTcok",
        "outputId": "6743a838-b909-4ba2-980f-45706ab25270",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libfontenc1 libxkbfile1 libxtst6 libxxf86dga1\n",
            "  openjdk-11-jre x11-utils\n",
            "Suggested packages:\n",
            "  openjdk-11-demo openjdk-11-source visualvm mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libfontenc1 libxkbfile1 libxtst6 libxxf86dga1\n",
            "  openjdk-11-jdk openjdk-11-jre x11-utils\n",
            "0 upgraded, 11 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 5,128 kB of archives.\n",
            "After this operation, 13.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/main amd64 fonts-dejavu-core all 2.37-1 [1,041 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/main amd64 fonts-dejavu-extra all 2.37-1 [1,953 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal/main amd64 libfontenc1 amd64 1:1.1.4-0ubuntu1 [14.0 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal/main amd64 libxkbfile1 amd64 1:1.1.0-1 [65.3 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu focal/main amd64 libxtst6 amd64 2:1.2.3-1 [12.8 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu focal/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu1 [12.0 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu focal/main amd64 x11-utils amd64 7.7+5 [199 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu focal/main amd64 libatk-wrapper-java all 0.37.1-1 [53.0 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu focal/main amd64 libatk-wrapper-java-jni amd64 0.37.1-1 [45.1 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 openjdk-11-jre amd64 11.0.18+10-0ubuntu1~20.04.1 [175 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 openjdk-11-jdk amd64 11.0.18+10-0ubuntu1~20.04.1 [1,559 kB]\n",
            "Fetched 5,128 kB in 2s (2,373 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 11.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "(Reading database ... 122349 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-dejavu-core_2.37-1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-1) ...\n",
            "Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../01-fonts-dejavu-extra_2.37-1_all.deb ...\n",
            "Unpacking fonts-dejavu-extra (2.37-1) ...\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "Preparing to unpack .../02-libfontenc1_1%3a1.1.4-0ubuntu1_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-0ubuntu1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../03-libxkbfile1_1%3a1.1.0-1_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../04-libxtst6_2%3a1.2.3-1_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1) ...\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "Preparing to unpack .../05-libxxf86dga1_2%3a1.1.5-0ubuntu1_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu1) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../06-x11-utils_7.7+5_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+5) ...\n",
            "Selecting previously unselected package libatk-wrapper-java.\n",
            "Preparing to unpack .../07-libatk-wrapper-java_0.37.1-1_all.deb ...\n",
            "Unpacking libatk-wrapper-java (0.37.1-1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
            "Preparing to unpack .../08-libatk-wrapper-java-jni_0.37.1-1_amd64.deb ...\n",
            "Unpacking libatk-wrapper-java-jni:amd64 (0.37.1-1) ...\n",
            "Selecting previously unselected package openjdk-11-jre:amd64.\n",
            "Preparing to unpack .../09-openjdk-11-jre_11.0.18+10-0ubuntu1~20.04.1_amd64.deb ...\n",
            "Unpacking openjdk-11-jre:amd64 (11.0.18+10-0ubuntu1~20.04.1) ...\n",
            "Selecting previously unselected package openjdk-11-jdk:amd64.\n",
            "Preparing to unpack .../10-openjdk-11-jdk_11.0.18+10-0ubuntu1~20.04.1_amd64.deb ...\n",
            "Unpacking openjdk-11-jdk:amd64 (11.0.18+10-0ubuntu1~20.04.1) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu1) ...\n",
            "Setting up openjdk-11-jre:amd64 (11.0.18+10-0ubuntu1~20.04.1) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-0ubuntu1) ...\n",
            "Setting up fonts-dejavu-core (2.37-1) ...\n",
            "Setting up fonts-dejavu-extra (2.37-1) ...\n",
            "Setting up openjdk-11-jdk:amd64 (11.0.18+10-0ubuntu1~20.04.1) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1) ...\n",
            "Setting up x11-utils (7.7+5) ...\n",
            "Setting up libatk-wrapper-java (0.37.1-1) ...\n",
            "Setting up libatk-wrapper-java-jni:amd64 (0.37.1-1) ...\n",
            "Processing triggers for mime-support (3.64ubuntu1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-2ubuntu3) ...\n"
          ]
        }
      ],
      "source": [
        "# !sudo add-apt-repository ppa:openjdk-r/ppa\n",
        "!sudo apt-get install openjdk-11-jdk\n",
        "# To Install Oracke JDK varsion 8\n",
        "# !sudo add-apt-repository ppa:webupd8team/java\n",
        "# !sudo apt-get install oracle-java8-installer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHCE-bUl_5YT",
        "outputId": "fdd89dae-5213-4bb8-d892-e46f29f7c0a7",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824028 sha256=c5650a8868e5edf70142ade7520858f140e1c53e262f40b50debb3f3ac9fa37b\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/e3/9b/0525ce8a69478916513509d43693511463c6468db0de237c86\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "  Attempting uninstall: py4j\n",
            "    Found existing installation: py4j 0.10.9.7\n",
            "    Uninstalling py4j-0.10.9.7:\n",
            "      Successfully uninstalled py4j-0.10.9.7\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.9/dist-packages (9.0.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.9/dist-packages (from pyarrow) (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.5/462.5 KB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tf-estimator-nightly\n",
            "Successfully installed tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        }
      ],
      "source": [
        "# !wget -q https://downloads.apache.org/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "# !tar xvzf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install pyspark\n",
        "!pip install -q findspark\n",
        "!pip install pyarrow\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  !pip install  tf-estimator-nightly==2.8.0.dev2021122109\n",
        "except Exception:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PyFhdHcmFlQg",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "OVQK8VGjl_jG",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import *\n",
        "import io\n",
        "\n",
        "from tensorflow.keras.applications.imagenet_utils import decode_predictions\n",
        "import pandas as pd\n",
        "from pyspark.sql.functions import col, pandas_udf, PandasUDFType\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "import pathlib\n",
        "import findspark\n",
        "from pyspark.sql import SparkSession\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "\n",
        "findspark.init()\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWwR0qo5bqr6"
      },
      "source": [
        "Uploading CIFAR 10 set to the session and Preprocessing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ey0Z2ZZ_Pc0B",
        "outputId": "5a3baef6-24bb-43ef-ca1d-bb4ed4f86691",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-04-06 04:23:11--  https://www.cs.toronto.edu/%7Ekriz/cifar-10-python.tar.gz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 170498071 (163M) [application/x-gzip]\n",
            "Saving to: ‘cifar-10-python.tar.gz’\n",
            "\n",
            "cifar-10-python.tar 100%[===================>] 162.60M  14.3MB/s    in 13s     \n",
            "\n",
            "2023-04-06 04:23:26 (12.4 MB/s) - ‘cifar-10-python.tar.gz’ saved [170498071/170498071]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.cs.toronto.edu/%7Ekriz/cifar-10-python.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLg6kn45PgCU",
        "outputId": "03a93246-3c64-46c1-e4b8-20f75c4593a0",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cifar-10-batches-py/\n",
            "cifar-10-batches-py/data_batch_4\n",
            "cifar-10-batches-py/readme.html\n",
            "cifar-10-batches-py/test_batch\n",
            "cifar-10-batches-py/data_batch_3\n",
            "cifar-10-batches-py/batches.meta\n",
            "cifar-10-batches-py/data_batch_2\n",
            "cifar-10-batches-py/data_batch_5\n",
            "cifar-10-batches-py/data_batch_1\n"
          ]
        }
      ],
      "source": [
        "!tar xvf cifar-10-python.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sVYtR1XfPmEO",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "from PIL import Image as im\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "def feature_extractor(batch_id):\n",
        "  \n",
        "  batch_file = open('./cifar-10-batches-py/data_batch_' + str(batch_id), mode='rb') \n",
        "    \n",
        "  batch = pickle.load(batch_file, encoding='latin1')\n",
        "      \n",
        "  features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
        "  labels = batch['labels']\n",
        "\n",
        "  return features, labels\n",
        "\n",
        "def write_imagenet_format(features_stack, labels_stack, data_path):\n",
        "  classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "  if not os.path.exists(data_path):\n",
        "    os.makedirs(data_path)\n",
        "\n",
        "  for item in classes:\n",
        "    sub_folder = os.path.join(data_path,item)\n",
        "    if not os.path.exists(sub_folder):\n",
        "      os.mkdir(sub_folder)\n",
        "\n",
        "  for i in range(features_stack.shape[0]):\n",
        "    samp = features_stack[i]\n",
        "    item = np.squeeze(labels_stack[i])\n",
        "    data = im.fromarray(samp, 'RGB')\n",
        "    data_save_path = os.path.join(data_path,classes[item],str(i)+'.jpg')\n",
        "    data.save(data_save_path)\n",
        "\n",
        "features_temp = np.array([])\n",
        "labels_temp = np.array([])\n",
        "\n",
        "for batch_id in range(1,6):\n",
        "  features, labels = feature_extractor( batch_id)\n",
        "  labels = np.expand_dims(np.squeeze(labels),1)\n",
        "  if batch_id != 1:\n",
        "    features_stack = np.vstack([features_temp, features])\n",
        "    labels_stack = np.vstack([labels_temp, labels])\n",
        "    features_temp = features_stack\n",
        "    labels_temp = labels_stack\n",
        "  else:\n",
        "    features_temp = features\n",
        "    labels_temp = labels\n",
        "  \n",
        "\n",
        "\n",
        "train_path = 'cifar_10_data/train_data'\n",
        "write_imagenet_format(features_stack, labels_stack, train_path)\n",
        "\n",
        "\n",
        "test_file =  open('./cifar-10-batches-py/test_batch', mode='rb')\n",
        "batch = pickle.load(test_file, encoding='latin1')\n",
        "test_features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
        "test_labels = batch['labels']\n",
        "\n",
        "test_path = 'cifar_10_data/test_data'\n",
        "write_imagenet_format(test_features, test_labels, test_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twAETGtMcFAQ"
      },
      "source": [
        "Recursively Read all the Images from the Parent directory and create a DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-Jh-li0V3al",
        "outputId": "ca4a4a48-468b-402e-e848-44312dcd25e8",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pyspark.sql.dataframe.DataFrame'>\n"
          ]
        }
      ],
      "source": [
        "images = spark.read.format(\"binaryFile\").option(\"recursiveFileLookup\", \"true\").option(\"pathGlobFilter\", \"*.jpg\").load('./cifar_10_data/train_data')\n",
        "print(type(images))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIpI0dx4BHdB",
        "outputId": "36a47ac2-52d9-4440-cc5c-f74223255c2c",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+------+--------------------+\n",
            "|                path|    modificationTime|length|             content|\n",
            "+--------------------+--------------------+------+--------------------+\n",
            "|file:/content/cif...|2023-04-06 04:23:...|  1124|[FF D8 FF E0 00 1...|\n",
            "|file:/content/cif...|2023-04-06 04:23:...|  1121|[FF D8 FF E0 00 1...|\n",
            "|file:/content/cif...|2023-04-06 04:23:...|  1118|[FF D8 FF E0 00 1...|\n",
            "|file:/content/cif...|2023-04-06 04:23:...|  1111|[FF D8 FF E0 00 1...|\n",
            "|file:/content/cif...|2023-04-06 04:23:...|  1104|[FF D8 FF E0 00 1...|\n",
            "+--------------------+--------------------+------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "images.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCL7nq9_BWeK",
        "outputId": "5439a470-543d-4e92-9284-c3ccb6deb8ff",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['file:/content/cifar_10_data/train_data/frog/14231.jpg',\n",
              " 'file:/content/cifar_10_data/train_data/bird/29920.jpg',\n",
              " 'file:/content/cifar_10_data/train_data/truck/1827.jpg',\n",
              " 'file:/content/cifar_10_data/train_data/automobile/44107.jpg',\n",
              " 'file:/content/cifar_10_data/train_data/truck/40040.jpg',\n",
              " 'file:/content/cifar_10_data/train_data/truck/6275.jpg',\n",
              " 'file:/content/cifar_10_data/train_data/truck/33639.jpg',\n",
              " 'file:/content/cifar_10_data/train_data/frog/2898.jpg',\n",
              " 'file:/content/cifar_10_data/train_data/airplane/43875.jpg',\n",
              " 'file:/content/cifar_10_data/train_data/automobile/1421.jpg']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "files=images.select('path').rdd.map(lambda x :x.path ).collect()\n",
        "files[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekKZzpVPha5M",
        "outputId": "12c2baef-d9b8-4b1a-c717-a3c4bc57491c",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+----------+--------+--------------------+\n",
            "|                path|    modificationTime|     label|    size|             content|\n",
            "+--------------------+--------------------+----------+--------+--------------------+\n",
            "|file:/content/cif...|2023-04-06 04:23:...|      frog|{32, 32}|[FF D8 FF E0 00 1...|\n",
            "|file:/content/cif...|2023-04-06 04:23:...|      bird|{32, 32}|[FF D8 FF E0 00 1...|\n",
            "|file:/content/cif...|2023-04-06 04:23:...|     truck|{32, 32}|[FF D8 FF E0 00 1...|\n",
            "|file:/content/cif...|2023-04-06 04:23:...|automobile|{32, 32}|[FF D8 FF E0 00 1...|\n",
            "|file:/content/cif...|2023-04-06 04:23:...|     truck|{32, 32}|[FF D8 FF E0 00 1...|\n",
            "+--------------------+--------------------+----------+--------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def extract_label(path_col):\n",
        "  \"\"\"Extract label from file path using built-in SQL functions.\"\"\"\n",
        "  return regexp_extract(path_col, \"./cifar_10_data/train_data/([^/]+)\", 1)\n",
        "\n",
        "def extract_size(content):\n",
        "  \"\"\"Extract image size from its raw content.\"\"\"\n",
        "  image = Image.open(io.BytesIO(content))\n",
        "  return image.size\n",
        "\n",
        "@pandas_udf(\"width: int, height: int\")\n",
        "def extract_size_udf(content_series):\n",
        "  sizes = content_series.apply(extract_size)\n",
        "  return pd.DataFrame(list(sizes))\n",
        "\n",
        "df = images.select(\n",
        "  col(\"path\"),\n",
        "  col(\"modificationTime\"),\n",
        "  extract_label(col(\"path\")).alias(\"label\"),\n",
        "  extract_size_udf(col(\"content\")).alias(\"size\"),\n",
        "  col(\"content\"))\n",
        "\n",
        "\n",
        "df.show(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "4xnBLBH6vf_h",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "ima=images.select('content').rdd.map(lambda x: x.content).collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "yXMMNfU_wW3Y",
        "outputId": "ffdec5ed-cef4-4477-caeb-c70fa7e8fe46",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=32x32 at 0x7F3AD6279760>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "imgg = Image.open(io.BytesIO(ima[0]))\n",
        "imgg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jrDuJgc-oO8z",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "class ImageNetDataset(Dataset):\n",
        "  \"\"\"\n",
        "  Converts image contents into a PyTorch Dataset with standard ImageNet preprocessing.\n",
        "  \"\"\"\n",
        "  def __init__(self, contents):\n",
        "    self.contents = contents\n",
        "\n",
        "  def __len__(self):\n",
        "    \n",
        "    return len(self.contents)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self._preprocess(self.contents[index])\n",
        "\n",
        "  def _preprocess(self, content):\n",
        "    \"\"\"\n",
        "    Preprocesses the input image content using standard ImageNet normalization.\n",
        "    \n",
        "    See https://pytorch.org/docs/stable/torchvision/models.html.\n",
        "    \"\"\"\n",
        "    image = Image.open(io.BytesIO(content))\n",
        "    transform = transforms.Compose([\n",
        "      transforms.Resize(256),                         ### Smaller lenght is convertd to 256 \n",
        "      transforms.CenterCrop(224),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    return transform(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "kvHGxWr-oVDC",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "def imagenet_model_udf(model_fn):\n",
        "  \"\"\"\n",
        "  Wraps an ImageNet model into a Pandas UDF that makes predictions.\n",
        "  \n",
        "  You might consider the following customizations for your own use case:\n",
        "    - Tune DataLoader's batch_size and num_workers for better performance.\n",
        "    - Use GPU for acceleration.\n",
        "    - Change prediction types.\n",
        "  \"\"\"\n",
        "  def predict(content_series_iter : pd.Series) -> pd.DataFrame:\n",
        "    model = model_fn() \n",
        "    model.eval()      \n",
        "    for content_series in content_series_iter:                                                    #Iterates overall all Images \n",
        "      dataset = ImageNetDataset(list(content_series))                                           \n",
        "      loader = DataLoader(dataset, batch_size=64) \n",
        "      with torch.no_grad():\n",
        "        for image_batch in loader:\n",
        "          predictions = model(image_batch).numpy()                                                # Predictions for all 1000 classes of Mobilenetv2 Training Dataset\n",
        "          predicted_labels = [x[0] for x in decode_predictions(predictions, top=1)]                       \n",
        "          yield pd.DataFrame(predicted_labels)\n",
        "    \n",
        "        \n",
        "  return_type = \"class: string, desc: string, score:float\"\n",
        "  # return_type = \"class: string\"                                         # SCALAR_ITER implies the function accepts list/array of scalar values as input.\n",
        "  return pandas_udf(predict,return_type, PandasUDFType.SCALAR_ITER)   \n",
        "  # return pandas_udf(return_type, PandasUDFType.SCALAR_ITER)(predict)   \n",
        "  \n",
        "  #Returns a Predict function object as the final user defined function object.\n",
        "  #Iterates over an Image: A sequence of bytes represented as a 2D array. \n",
        "  #Scalar is a series of bytes.    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "pNsdZIiK0E9F",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using Imagenet Model to make predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fevQ4pyg0w7P",
        "outputId": "6661dc49-adc1-4595-d7f8-941ace683675",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pyspark/sql/pandas/functions.py:394: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "predictions_class_imagenet =[]\n",
        "predictions_count_imagenet = []\n",
        "\n",
        "imagenet_udf = imagenet_model_udf(lambda: models.mobilenet_v2(pretrained=True))\n",
        "predictions = df.withColumn(\"prediction\", imagenet_udf(col(\"content\")))\n",
        "prediction_imagenet = predictions.select(col(\"label\").alias('Class'),col(\"prediction.desc\").alias(\"Imagenet prediction\"))\n",
        "pred_df = prediction_imagenet.limit(1000).toPandas() #Limiting to convert only the first 1000 rows into pandas dataframe to increase speed of the model\n",
        "for item in classes:\n",
        "  rows_df = pred_df.loc[pred_df['Class'] == item]\n",
        "  predicted_class_count = rows_df['Imagenet prediction'].value_counts().nlargest(1).tolist()[0]\n",
        "  predicted_class = rows_df['Imagenet prediction'].value_counts().nlargest(1).keys().tolist()[0] # Assign the label with highest count frequency as the predicted label\n",
        "  predictions_class_imagenet.append(predicted_class)\n",
        "  predictions_count_imagenet.append(predicted_class_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nc5wfmfJYP9i",
        "outputId": "2c0bdd63-d16f-43df-807d-48b6f24fa1a3",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------------+-------------------------+\n",
            "|Actual Class Label|Imagenet Prediction Label|\n",
            "+------------------+-------------------------+\n",
            "|          airplane|                chain_saw|\n",
            "|        automobile|               moving_van|\n",
            "|              bird|             fox_squirrel|\n",
            "|               cat|              EntleBucher|\n",
            "|              deer|                  cardoon|\n",
            "|               dog|         Japanese_spaniel|\n",
            "|              frog|              rock_python|\n",
            "|             horse|                   sorrel|\n",
            "|              ship|               moving_van|\n",
            "|             truck|               moving_van|\n",
            "+------------------+-------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tuple_list_imagenet = list(zip(classes,predictions_class_imagenet))\n",
        "imagenet_df = spark.createDataFrame(tuple_list_imagenet, ['Actual Class Label', 'Imagenet Prediction Label'])\n",
        "imagenet_df.show() #Displaying the final prediction of the pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "PVhyB0__Wtva",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wh0u3KBXo__S"
      },
      "source": [
        "Experimentation with different Models:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "jldQ9blR8NqX",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "model_class = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "1i1WE9dUAcQp",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "predictions_class =[]\n",
        "predictions_count = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ooNPw1TXYbh",
        "outputId": "8965f665-be3f-48f7-b6d0-8658f7b83de2",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pyspark/sql/pandas/functions.py:394: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "densenet121_udf = imagenet_model_udf(lambda: models.densenet121(pretrained=True))\n",
        "predictions = df.withColumn(\"prediction\", densenet121_udf(col(\"content\")))\n",
        "predictions_densenet121 = predictions.select(col(\"label\"),col(\"prediction.desc\").alias(\"densenet121 prediction\"))\n",
        "pred_dense_df = predictions_densenet121.limit(1000).toPandas()\n",
        "top_num = 3\n",
        "for item in classes:\n",
        "  rows_df = pred_dense_df.loc[pred_dense_df['label'] == item]\n",
        "  predicted_class_count = rows_df['densenet121 prediction'].value_counts().nlargest(1).tolist()[0]\n",
        "  predicted_class = rows_df['densenet121 prediction'].value_counts().nlargest(1).keys().tolist()[0]\n",
        "  predictions_class.append(predicted_class)\n",
        "  predictions_count.append(predicted_class_count)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Q2x7ueyEBZOK",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "predictions_class_alexnet =[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CA0iRTbxY0MA",
        "outputId": "9577b6d7-a8f9-4d73-f953-5f8711a7cdfa",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pyspark/sql/pandas/functions.py:394: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "alexnet_udf = imagenet_model_udf(lambda: models.alexnet(pretrained=True))\n",
        "predictions = df.withColumn(\"prediction\", alexnet_udf(col(\"content\")))\n",
        "predictions_alexnet = predictions.select(col(\"label\"),col(\"prediction.desc\").alias(\"alexnet prediction\"))\n",
        "pred_alex_df = predictions_alexnet.limit(1000).toPandas()\n",
        "top_num = 3\n",
        "for item in classes:\n",
        "  filt_rows = pred_alex_df.loc[pred_alex_df['label'] == item]\n",
        "  predicted_class_count = filt_rows['alexnet prediction'].value_counts().nlargest(1).tolist()[0]\n",
        "  predicted_class = filt_rows['alexnet prediction'].value_counts().nlargest(1).keys().tolist()[0]\n",
        "  predictions_class_alexnet.append(predicted_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "YkKB2l4vCfzM",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "predictions_class_shufflenet =[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtbDCfz1ZltY",
        "outputId": "dbc8db5f-6b5d-4013-953e-9db6e2062c80",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pyspark/sql/pandas/functions.py:394: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "shufflenet_udf = imagenet_model_udf(lambda: models.shufflenet_v2_x1_0(pretrained=True))\n",
        "predictions = df.withColumn(\"prediction\", shufflenet_udf(col(\"content\")))\n",
        "predictions_shufflenet = predictions.select(col(\"label\"),col(\"prediction.desc\").alias(\"shufflenet prediction\"))\n",
        "ser_df = predictions_shufflenet.limit(1000).toPandas()\n",
        "top_num = 3\n",
        "for item in classes:\n",
        "  filt_rows = ser_df.loc[ser_df['label'] == item]\n",
        "  predicted_class_count = filt_rows['shufflenet prediction'].value_counts().nlargest(1).tolist()[0]\n",
        "  predicted_class = filt_rows['shufflenet prediction'].value_counts().nlargest(1).keys().tolist()[0]\n",
        "  predictions_class_shufflenet.append(predicted_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Li7xUdUBDN74",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "predictions_class_resnet50 =[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PwhQ30ahe2S",
        "outputId": "ce63bdec-1268-45e3-ad08-f4881e4533f2",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pyspark/sql/pandas/functions.py:394: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "resnet50_udf = imagenet_model_udf(lambda: models.resnet50(pretrained=True))\n",
        "predictions = df.withColumn(\"prediction\", resnet50_udf(col(\"content\")))\n",
        "predictions_resnet50 = predictions.select(col(\"label\"),col(\"prediction.desc\").alias(\"resnet50 prediction\"))\n",
        "ser_df = predictions_resnet50.limit(1000).toPandas()\n",
        "top_num = 3\n",
        "for item in classes:\n",
        "  filt_rows = ser_df.loc[ser_df['label'] == item]\n",
        "  predicted_class_count = filt_rows['resnet50 prediction'].value_counts().nlargest(1).tolist()[0]\n",
        "  predicted_class = filt_rows['resnet50 prediction'].value_counts().nlargest(1).keys().tolist()[0]\n",
        "  predictions_class_resnet50.append(predicted_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "mXwAlkPWnpPC",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "tuple_list = list(zip(classes,predictions_class, predictions_class_alexnet, predictions_class_shufflenet,predictions_class_resnet50))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "9dQgmmC6FI9U",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "models_df = spark.createDataFrame(tuple_list, ['Actual Class', 'Densenet Prediction', 'Alexnet Prediction','Shufflenet Prediction','Resnet50 Prediction'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2b8v7-0FaOb",
        "outputId": "73e46c44-22ed-44c6-e7e3-c0f448c84e52",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------+-------------------+--------------------+---------------------+-------------------+\n",
            "|Actual Class|Densenet Prediction|  Alexnet Prediction|Shufflenet Prediction|Resnet50 Prediction|\n",
            "+------------+-------------------+--------------------+---------------------+-------------------+\n",
            "|    airplane|           airliner|             panpipe|          Windsor_tie|      letter_opener|\n",
            "|  automobile|         moving_van|          moving_van|           moving_van|         moving_van|\n",
            "|        bird|            limpkin|        fox_squirrel|               langur|            limpkin|\n",
            "|         cat|       fox_squirrel|    English_foxhound|               langur|       fox_squirrel|\n",
            "|        deer|             sorrel|      Dandie_Dinmont|              limpkin|        toy_terrier|\n",
            "|         dog|     Dandie_Dinmont|wire-haired_fox_t...|     Japanese_spaniel|   Japanese_spaniel|\n",
            "|        frog|       fox_squirrel|        fox_squirrel|         fox_squirrel|        tailed_frog|\n",
            "|       horse|             sorrel|              sorrel|      Indian_elephant|             sorrel|\n",
            "|        ship|          speedboat|          moving_van|          Windsor_tie|         moving_van|\n",
            "|       truck|         moving_van|          moving_van|           moving_van|         moving_van|\n",
            "+------------+-------------------+--------------------+---------------------+-------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "models_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzE6Xbh0FfEO",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
